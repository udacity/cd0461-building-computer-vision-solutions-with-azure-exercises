{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please install the required Python modules/SDKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! activate ai-azure-c1\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/opt/conda/envs/ai-azure-c1/lib/python3.8/site-packages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This demo uses the latest pillow package to show the rectangular bounding box around the face, so please upgrade the pillow package using the command below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pillow==8.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Useful Python Libraries or Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import glob, os, sys, time, uuid\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType\n",
    "from msrest.authentication import CognitiveServicesCredentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Specific Azure Resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVKASH_FACE_KEY = \"ENTER FACE SERVICE RESOURCE KEY\"\n",
    "AVKASH_FACE_ENDPOINT = \"ENTER FACE SERVICE RESOURCE ENDPOINT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client\n",
    "face_client = FaceClient(AVKASH_FACE_ENDPOINT, CognitiveServicesCredentials(AVKASH_FACE_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_client.api_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, upload several images of your own to this workspace and modify the code below as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls human-face*.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_face_images = [file for file in glob.glob('*.jpg') if file.startswith(\"human-face\")]\n",
    "print(my_face_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img in my_face_images:\n",
    "    with open(img, 'rb') as img_code:\n",
    "        img_view_ready = Image.open(img_code)\n",
    "        plt.figure()\n",
    "        plt.imshow(img_view_ready)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Person Model Based on your face images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSON_GROUP_ID = str(uuid.uuid4())\n",
    "person_group_name = 'ENTER YOUR PERSON GROUP NAME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code is taken from Azure face SDK \n",
    "## ---------------------------------------\n",
    "def build_person_group(client, person_group_id, pgp_name):\n",
    "    print('Create and build a person group...')\n",
    "    # Create empty Person Group. Person Group ID must be lower case, alphanumeric, and/or with '-', '_'.\n",
    "    print('Person group ID:', person_group_id)\n",
    "    client.person_group.create(person_group_id = person_group_id, name=person_group_id)\n",
    "\n",
    "    # Create a person group person.\n",
    "    my_face = client.person_group_person.create(person_group_id, pgp_name)\n",
    "    # Find all jpeg images of human in working directory.\n",
    "    my_face_images = [file for file in glob.glob('*.jpg') if file.startswith(\"human-face\")]\n",
    "    # Add images to a Person object\n",
    "    for image_p in my_face_images:\n",
    "        with open(image_p, 'rb') as w:\n",
    "            client.person_group_person.add_face_from_stream(person_group_id, my_face.person_id, w)\n",
    "\n",
    "    # Train the person group, after a Person object with many images were added to it.\n",
    "    client.person_group.train(person_group_id)\n",
    "\n",
    "    # Wait for training to finish.\n",
    "    while (True):\n",
    "        training_status = client.person_group.get_training_status(person_group_id)\n",
    "        print(\"Training status: {}.\".format(training_status.status))\n",
    "        if (training_status.status is TrainingStatusType.succeeded):\n",
    "            break\n",
    "        elif (training_status.status is TrainingStatusType.failed):\n",
    "            client.person_group.delete(person_group_id=PERSON_GROUP_ID)\n",
    "            sys.exit('Training the person group has failed.')\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_person_group(face_client, PERSON_GROUP_ID, person_group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making sure the person model has faces and they all belong to the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detect all faces in query image list, then add their face IDs to a new list.\n",
    "'''\n",
    "def detect_faces(client, query_images_list):\n",
    "    print('Detecting faces in query images list...')\n",
    "\n",
    "    face_ids = {} # Keep track of the image ID and the related image in a dictionary\n",
    "    for image_name in query_images_list:\n",
    "        image = open(image_name, 'rb') # BufferedReader\n",
    "        print(\"Opening image: \", image.name)\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Detect the faces in the query images list one at a time, returns list[DetectedFace]\n",
    "        faces = client.face.detect_with_stream(image)  \n",
    "\n",
    "        # Add all detected face IDs to a list\n",
    "        for face in faces:\n",
    "            print('Face ID', face.face_id, 'found in image', os.path.splitext(image.name)[0]+'.jpg')\n",
    "            # Add the ID to a dictionary with image name as a key.\n",
    "            # This assumes there is only one face per image (since you can't have duplicate keys)\n",
    "            face_ids[image.name] = face.face_id\n",
    "\n",
    "    return face_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's view the face-specific thumbnails "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = detect_faces(face_client, my_face_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify that 2 random images from the list belong to the same person\n",
    "- ### Note: Modify your image file name if you see fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification example for faces of the same person.\n",
    "verify_result = face_client.face.verify_face_to_face(ids['human-face1.jpg'], ids['human-face2.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verify_result.is_identical:\n",
    "    print(\"Faces are of the same (Positive) person, similarity confidence: {}.\".format(verify_result.confidence))\n",
    "else:\n",
    "    print(\"Faces are of different (Negative) persons, similarity confidence: {}.\".format(verify_result.confidence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match face from ID card with face from Video Analyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_cell(face_url):\n",
    "    response = requests.get(face_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own image URL\n",
    "dl_source_url = 'https://raw.githubusercontent.com/udacity/cd0461-building-computer-vision-solutions-with-azure-exercises/main/resources/ca-dl-sample.png'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image_in_cell(dl_source_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## -------\n",
    "## Reading file locally\n",
    "## -------\n",
    "# If I had image file locally I would have used the following method\n",
    "# dl_image = open('/your-local-file-system/udacity/cal-dl.png', 'rb')\n",
    "# dl_faces = face_client.face.detect_with_stream(dl_image)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_faces = face_client.face.detect_with_url(dl_source_url) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Face ID and then save it into the list of already saved Face IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face in dl_faces:\n",
    "    print('Face ID', face.face_id, 'found in image', dl_source_url)\n",
    "    # Add the ID to a dictionary with image name as a key.\n",
    "    # This assumes there is only one face per image (since you can't have duplicate keys)\n",
    "    ids['ca-dl-sample.png'] = face.face_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, you have (n + 1) Face IDs in your Face ID list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform face verification between the 1 Face ID and the n Face IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification example for faces of the same person.\n",
    "dl_verify_result = face_client.face.verify_face_to_face(ids['human-face4.jpg'], ids['ca-dl-sample.png'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dl_verify_result.is_identical:\n",
    "    print(\"Faces are of the same (Positive) person, similarity confidence: {}.\".format(dl_verify_result.confidence))\n",
    "else:\n",
    "    print(\"Faces are of different (Negative) persons, similarity confidence: {}.\".format(dl_verify_result.confidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids['ca-dl-sample.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_faces[0].face_rectangle.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKEN FROM THE Azure SDK Sample\n",
    "# Convert width height to a point in a rectangle\n",
    "def getRectangle(faceDictionary):\n",
    "    rect = faceDictionary.face_rectangle\n",
    "    left = rect.left\n",
    "    top = rect.top\n",
    "    right = left + rect.width\n",
    "    bottom = top + rect.height\n",
    "    \n",
    "    return ((left, top), (right, bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawFaceRectangles(source_file, detected_face_object) :\n",
    "    # Download the image from the url\n",
    "    response = requests.get(source_file)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    # Draw a red box around every detected faces\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for face in detected_face_object:\n",
    "        draw.rectangle(getRectangle(face), outline='red', width = 10)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawFaceRectangles(dl_source_url, dl_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match Face ID from the face image URL with Person Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of Face ID\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter the face ID of ca-dl-sample.png from the output of the cell above\n",
    "get_the_face_id_from_the_driving_license = 'ENTER FACE ID HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_gp_results = face_client.face.identify([get_the_face_id_from_the_driving_license], PERSON_GROUP_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in person_gp_results:\n",
    "    for candidate in result.candidates:\n",
    "        print(\"The Identity match confidence is {}\".format(candidate.confidence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
